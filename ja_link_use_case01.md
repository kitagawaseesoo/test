---
layout: ja/link/use_case01
title: 利用事例 - 関連情報 | ABCI
permalink: /ja/link/use_case01.html
---


## 利用事例
{: .h2 }

<p class="f18">連載Ｘ回：国立研究開発法人 日本原子力研究開発機構(JAEA) 様</p>
<h3 class="h3n">大規模シミュレーションと深層学習で、超高速の風予報を</h3>

国立研究開発法人 日本原子力研究開発機構（JAEA）様は、日本で唯一の原子力に関する総合的研究開発機関です。ABCI利用者の声、今回は 同機構)高度計算機技術開発室で、都市レベルの風 の流体解析の研究に挑まれている小野寺様と、室長の井戸村様にお話を伺いました。
<br /><br />
<div align="center">
	<img src="../../img/link/sample1.jpg" alt=""><br /><br />
国立研究開発法人　日本原子力開発研究機構<br />
システム計算科学センター高度計算機技術開発室長　井戸村 泰宏 様(右)<br />
システム計算科学センター高度計算機技術開発室	　小野寺 直幸 様(左)

</div><br />

<h3 class="h3n">放射性物質の拡散をシミュレーション</h3>

<dl class="interview ns">
	<dt>ー　どのような研究に、ABCIを使っているのでしょうか。</dt>
	<dd>小野寺 直幸 様（以下、小野寺）: リアルタイムで風を解析することを目指しています。日本原子力研究開発機構ですので、核セキュリティに役立つ研究です。
	</dd>
</dl>

<dl class="interview ns">
	<dt>ー　核セキュリティとはどんなことですか？</dt>
	<dd>小野寺:放射性物質が環境に放出される状況は、事故やテロなどが考えられますが、いまニーズが高いのは原子力発電所の廃炉作業です。作業が進むと、いろいろな設備が取り払われていきます。その中で放射性物質の環境放出が増えないよう、工程を調整しながら作業していきますが、万一放出された場合にどのくらい影響があるか事前に評価する必要があります。<br />
	<br />
	機構としての目的はこういったことですが、科学的な興味もあります。これは1mの解像度で、東京都心のビル1個1個をとらえた風のシミュレーションです。現在はリアルタイムで、シミュレーション内の時間と同じ時間での解析を目指していますが、深層学習を利用してその10倍、100倍といった速さで大規模な予測ができ、何か災害が起きたときに拡散を予想することができたらいいなと考えていやっています。
	<br /><br />
		<div align="center">
			<img src="../../img/link/sample2.jpg" alt=""><br />
			図1．東京都心の風シミュレーション
		</div><br />
		現在は深層学習というよりは、大型計算機を使った数値流体解析を行っている段階です。主に用いている計算資源は東京工業大学のTSUBAMEとABCIで、どちらもGPUを搭載したスーパーコンピューターですので、GPUに適した計算手法を作っています。気象予報の格子は500m、1kmといったスケールなので、それを1mの解像度の細かい格子とつなぐような手法も同時に開発しています。<br />
		<br />
		TSUBAMEとABCIではGPUの世代が違いますし、ちょっとネットワークの形が違っていたりします。それらを比較することで、将来的により高性能のシステムができたときに、より詳細なリアルタイム計算がより少ないGPUでできるとか、より短時間でできることを目指した性能測定も行っています。</dd>
</dl>

<h3 class="h3n">大規模コンピューティングの鍵を握る、通信速度</h3>

<div align="center">
	<img src="../../img/link/sample3.jpg" alt="">
</div><br />

<dl class="interview ns">
	<dt>ー　コンピューターの性能をより引き出すには、どのような手法があるのでしょうか。</dt>
	<dd>井戸村 泰宏 様（以下、井戸村）:スケーリング（拡張性）の性能測定にはウィークスケーリングと、ストロングスケーリングがあります。ウィークスケーリングでは1つのGPUに決まった大きさの問題を解かせるので、GPUの数を増やしていくと問題の大きさは大きくなりますが、1つのGPUが解く計算量は変わらないので処理時間は変わりません。<br />
	<br />
	ストロングスケーリングでは、逆に問題全体の大きさを設定して、GPUの数を増やしていきます。すると1つのGPUあたりの計算量が減っていくので、処理時間が減っていきます。ウィークスケーリングはどれだけ大きな問題を解くことができるか、ストロングスケーリングはそれだけ計算を加速できるか、という違いです。<br />
	<br />
	小野寺:ウィークスケーリングとストロングスケーリングの両方で、TSUBAMEとABCIを使って性能を測定しています。ウィークスケーリングでは1GPUあたりの計算量は同じなので、GPUの数に比例して性能が伸びていきますが、同じ196GPUでは、ABCIではTSUBAMEの1.57倍の高速計算ができました。ストロングスケーリングでは解析する広さを2km×2km×高さ1kmで固定して、GPUを増やしていきます。そうすると1つのGPUが受け持つメモリーの体積に対して、通信の表面積は大きくなっていくので…

	</dd>
</dl>

<dl class="interview ns">
	<dt>ー　メモリーの体積と通信の表面積って、どういうことですか？</dt>
	<dd>小野寺：3次元シミュレーションなので、計算量は解析する空間の体積で決まります。その計算領域を各GPUに割り当てると、隣の領域と通信が必要になるので、通信量は表面積になるのです。</dd>
</dl>


<dl class="interview ns">
	<dt>ー　なるほど。シミュレーションの領域を分割してGPUに計算させると、隣接した領域を計算しているGPUとの間で、計算結果を交換しなければならないから、分割するほどGPU間の通信量が増えていくのですね。</dt>
	<dd>小野寺:ストロングスケーリングの場合、GPUの演算性能だけでなく通信性能もすごく重要になってきますので、通信の削減手法を用いることでストロングスケーリングに強いアルゴリズムを作りました。リアルタイム計算をするのにTSUBAMEでは400GPUが必要だったのですが、この手法を用いることで100GPUでできるようになりました。ABCIだと、135GPUだったのが60GPUでできるようになった。
	</dd>
</dl>

<dl class="interview ns">
	<dt>ー　TSUBAMEとABCIの性能差で比較すると、もともとTSUBAMEでは400GPU必要なのがABCIでは135GPUで同じ速度になり、アルゴリズム改善後は100GPUから60GPUということになりますね。</dt>
	<dd>小野寺:ABCIはGPUの世代が変わり、こちらが目的としているリアルタイム計算がよりコンパクトなシステムで実現できるようになりました。<br />
	<br />
	井戸村:京（理化学研究所のスーパーコンピュータ）と比べて、ABCIのプロセッサあたりの処理速度は60倍になっています。しかしプロセッサ間の通信速度は京が毎秒20GB、ABCIは毎秒25GBで、あまり違いがありません。だから、こういう大規模計算って演算も大変なのですが、演算が速すぎて通信が追い付いていないんです。それを解決するためにアルゴリズムを組んで性能を向上しました。一般に、シミュレーションをやっている人が一番苦労するところだと思います。

	</dd>
</dl>

<h3 class="h3n">シミュレーション結果をビッグデータとして深層学習</h3>


<dl class="interview ns">
	
	<dd>
		<div align="center">
			<img src="../../img/link/sample4.jpg" alt="">
		</div><br />
		小野寺:これは3km四方の地形データに風の情報を加えて、2m解像度で汚染物質の拡散をシミュレーションしたものです。こういうシミュレーションをリアルタイムぐらいでできるようになっています。次のターゲットとしては、このシミュレーション結果を使うことでリアルタイムの10倍、100倍と加速して、予報できるようなことをABCI上で一貫してできたらいいなと考えています。
建物ひとつひとつの細かい流れは、深層学習で予測できるという論文も結構あります。日々の気象データをリアルタイムでシミュレーションしていくと、膨大なビッグデータを生み出すことができますから。

	</dd>
	
	<dt>ー　リアルタイムでは予報に使えないから、建物の周りの風は厳密に計算しなくてもだいたいこうなるはずだ、というモデルを作ってしまおうと。
</dt>

	<dd>
	小野寺:そうですね。いろんな風の流れといろんな建物形状のパターンができたら、違う土地の建物データでもリアルタイム計算をせず、学習した結果から予報できるんじゃないか。いろんな都市でも即時予報ができるんじゃないかと見込んでいます。ドローンを飛ばすといったことと連携していけるのではないかと。

	</dd>
	<dt>ー　今のお話を伺うと、スーパーコンピューターの使い方として全く違う2つの使い方を組み合わせているわけですよね。厳密なシミュレーションと、それを基にしたビッグデータの深層学習。<br />
ビッグデータと言うと、現実のデータを収集して解析し学習するイメージだったのですが、シミュレーション結果もビッグデータになり得るのですね。
</dt>
</dl>

<h3 class="h3n">同じシステムで一貫して処理できるメリット</h3>
<dl class="interview ns">
	<dd>井戸村:現実のデータを膨大に用意するのは大変ですが、シミュレーションならいくらでも自在に作れてしまいます。しかも実験だと充分に広範囲なデータを取れない場合もありますが、シミュレーションは自在に風速を設定して、その範囲内の機械学習で済むようなデータベースを作れるのが一番大きな特徴かなと思います。
</dd>

	<dt>ー　なるほど、実データだと機械学習に使えるようなきれいなデータセットにするのに手間がかかると聞きますが、シミュレーションならきれいなデータを作るようにすればよいですね。
</dt>

	<dd>小野寺：そうです。同じ研究者が同じ計算機でやっていますから、データのどれがどういう意味を持つかということもはっきりわかっていますので、そういう意味では一貫しているのは大きいのかなと。
</dd>
	<dt>ー　同じ計算機でシミュレーションと深層学習をしていることにも意味があるのですか。
</dt>

	<dd>小野寺:大規模なシミュレーションをすると、数百TBのデータも簡単に作ることができますが、それを計算機間で移動させることってできないんです。あまりにもデータ量が大きすぎて、通信で送るのは現実的ではありません。そうなると、大規模シミュレーションと深層学習をする計算機はストレージを共有している必要があります。それを一貫してできるシステムはありがたいですね。
</dd>
</dl>

<h3 class="h3n">2000GPUの同時使用で、エクサスケール時代に迫るABCI</h3>
<div align="center">
	<img src="../../img/link/sample5.jpg" alt="">
</div><br />

<dl class="interview ns">
	<dt>ー　ABCIや他のスーパーコンピューターの中から、使用するシステムを選ぶ際にはどんな理由があるのですか？たまたまではない理由で…
</dt>
	<dd>小野寺：たまたまと言えばたまたまに近いところもあります（笑）。研究に計算機を無償使用できる制度がいくつかありますから、文科省の制度で課題を採択されればTSUBAMEを利用することがあります。採択されていなくても有償利用は可能です。
</dd>
</dl>

<dl class="interview ns">
	<dt>ー　単純にお金だけで決めるわけではないですよね。有償でもABCIを使っている。
</dt>
	<dd>小野寺：ABCIを使うのは明確な理由があります。いま、一般利用で2000GPUまで同時使用できるシステムは、日本にはほかにありません。世界的にもほとんどないですね。こういう最先端のシミュレーションを開発する環境として、ABCIは欠かせません。<br />
<br />
井戸村:現在のシミュレーション環境としてはもちろん、我々のセンターはエクサスケールコンピューティング（100京FLOPS規模のスーパーコンピューター）という、次世代のシミュレーション環境を視野に開発をしていて、そういうことを見据えるとやはり現在使える最大規模のシステムを使いたい。
</dd>
</dl>

<dl class="interview ns">
	<dt>ー　実際に役に立つものを作り出す研究だけでなく、まずコンピューターを使いこなすことそのものも研究対象になるのですね。</dt>
	<dd>井戸村:日本原子力機構が現時点で必要とする実用的なシミュレーションに、エクサスケールコンピューティングが必要なくても、そういう技術を開発することで次世代のシミュレーションに役立っていきます。<br />
京コンピューターのプロジェクトが始まった頃には、産業界ではパソコンレベルの開発しかやっていませんでした。京コンピューターで様々なアプリケーションが使えるようになったことで、産業界もスーパーコンピューターを使うようになってきています。

	</dd>
</dl>

<h3 class="h3n">研究から産業へ、応用を広げるABCI</h3>

<dl class="interview ns">
	<dt>ー　GPUを2000個同時に使えるABCIも、その能力を発揮できるような使い方をできる人がまだ産業界に少ないということですね。そのあたりで日本と外国の差はあるのでしょうか。
</dt>

	<dd>井戸村：GPUを利用するスーパーコンピューティングに関してはかなり、アメリカが進んでいます。日本では、CPUを使っている京コンピューターに力を入れてきたので、CPU主体の利用が進んでいます。アメリカでは前の世代からGPUスパコンをやっていて、GPUの方がメジャーになりつつある感じです。アメリカ発のフリーウェアやオープンソースのシミュレーションなどは、かなりGPU対応が進んできています。
</dd>
</dl>

<dl class="interview ns">
	<dt>ー　研究界から産業界へ、もっとスーパーコンピューティングを応用していくのはどのようなルートがあるのですか。</dt>

	<dd>小野寺:いろいろあると思いますが、たとえば産業応用のテーマに企業と連携してアプリケーションを開発して、共同で利用するようなこともあります。企業の実験装置で得られたデータをこちらのシミュレーションで解析するといったタイアップもあります。別のやり方で言うと、我々が開発したプログラムをオープンソースで提供し、それを使っていただくといった取り組みは積極的にやるようにしています。
</dd>
	<dt>ー　ABCIは深層学習やAIを主眼に置いて作られたシステムですが、それ専用ではなく同じコンピューターの中で、深層学習の元となるシミュレーションもできることが重要だというお話が、大変勉強になりました。
</dt>
</dl>
<br />
聞き手　大貫 剛（ライター）
